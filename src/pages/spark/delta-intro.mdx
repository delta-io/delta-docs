---
title: Introduction
description: Learn about Delta Lake features and resources to learn about Delta Lake.
menu: docs
---

[Delta Lake](https://delta.io) is an [open source
project](https://github.com/delta-io/delta) that enables building a [Lakehouse
architecture](https://databricks.com/blog/2020/01/30/what-is-a-data-lakehouse.html)
on top of [data lakes](https://databricks.com/discover/data-lakes/introduction).

Delta Lake provides [ACID transactions](concurrency-control.md), scalable
metadata handling, and unifies [streaming](delta-streaming.md) and
[batch](delta-batch.md) data processing on top of existing data lakes, such as
S3, ADLS, GCS, and HDFS.

For a quick overview and benefits of Delta Lake, watch this YouTube video (3
minutes).

\

.. youtube:: PftRBoqjhZM?rel=0

\

Specifically, Delta Lake offers:

- [ACID transactions](concurrency-control.md) on Spark: Serializable isolation
  levels ensure that readers never see inconsistent data.
- Scalable metadata handling: Leverages Spark distributed processing power to
  handle all the metadata for petabyte-scale tables with billions of files at
  ease.
- [Streaming](delta-streaming.md) and [batch](delta-batch.md) unification: A
  table in Delta Lake is a batch table as well as a streaming source and sink.
  Streaming data ingest, batch historic backfill, interactive queries all just
  work out of the box.
- Schema enforcement: Automatically handles schema variations to prevent
  insertion of bad records during ingestion.
- [Time travel](delta-batch.md#deltatimetravel): Data versioning enables
  rollbacks, full historical audit trails, and reproducible machine learning
  experiments.
- [Upserts](delta-update.md#delta-merge) and
  [deletes](delta-update.md#delta-delete): Supports merge, update and delete
  operations to enable complex use cases like change-data-capture,
  slowly-changing-dimension (SCD) operations, streaming upserts, and so on.

  For a general introduction and demonstration of Delta Lake, watch this YouTube
  video (51 minutes).

  \

  .. youtube:: a18C8kJfNrE?rel=0

  \

  Delta Engine optimizations make Delta Lake operations highly performant,
  supporting a variety of workloads ranging from large-scale ETL processing to
  ad-hoc, interactive queries. For information on Delta Engine, see
  [\_](optimizations/index.md).

  ## Quickstart

  The Delta Lake quickstart provides an overview of the basics of working with

  Delta Lake. The [quickstart](quick-start.md) shows how to load data into a
  Delta table, modify the table, read the table, display table history, and
  optimize the table.

  ## Key tasks

  The following list provides links to documentation for common Delta Lake tasks.

  - Create a Delta table: [quick start](quick-start.md#create-a-table), [as part
    of batch data tasks](delta-batch.md#create-a-table)
  - Load and write data into a Delta Lake table:

    - With [COPY INTO](delta-ingest.md#copy-into-sql-command)
    - With [Auto Loader](delta-ingest.md#auto-loader)
    - With the [Create Table UI in Databricks
      SQL](/sql/user/create-table/index.md).

    - With streaming: [quick start](quick-start.md#stream-writes-to-a-table),
      [as part of streaming](delta-streaming.md)

      - With third-party solutions: [with
        partners](delta-ingest.md#partner-integrations), [with third-party
        providers](integrations.md)

    - [Update data](delta-update.md#update-a-table)
    - Merge data updates and insertions (upserts): [quick
      start](quick-start.md#batch-upserts), [as part of table
      updates](delta-update.md#upsert-into-a-table-using-merge)
    - [Append data](delta-batch.md#append)
    - [Overwrite data](delta-batch.md#overwrite)

  - [Convert a Parquet table to a Delta
    table](delta-utility.md#convert-a-parquet-table-to-a-delta-table)
  - Read data from a Delta table: [quick start](quick-start.md#read-a-table),
    [as part of batch data tasks](delta-batch.md#read-a-table), [as part of
    streaming](delta-streaming.md)
  - Optimize a Delta table: [quick start](quick-start.md#optimize-a-table), [as
    part of bin packing](optimizations/file-mgmt.md#compaction-bin-packing), [as
    part of
    Z-ordering](optimizations/file-mgmt.md#z-ordering-multi-dimensional-clustering),
    [as part of file size tuning](optimizations/file-mgmt.md#tune-file-size)
  - [Create a view on top of a Delta table](delta-batch.md#views-on-tables)
  - [Delete data from a Delta table](delta-update.md#delete-from-a-table)
  - [Display Delta table details](delta-utility.md#retrieve-delta-table-details)
  - Display the history of a Delta table: [quick
    start](quick-start.md#display-table-history), [as part of data
    utilities](delta-utility.md#retrieve-delta-table-history)
  - Clean up Delta table snapshots (vacuum): [quick
    start](quick-start.md#clean-up-snapshots), [as part of data
    utilities](delta-utility.md#remove-files-no-longer-referenced-by-a-delta-table)
  - Work with Delta table columns:
    - [Work with column constraints](delta-constraints.md#not-null-constraint)
    - Partition data by columns: [quick start](quick-start.md#partition-data),
      [as part of batch data tasks](delta-batch.md#partition-data)
    - [Use automatically-generated
      columns](delta-batch.md#use-generated-columns)
    - [Update columns (add, reorder, replace, rename, change
      type)](delta-batch.md#update-table-schema)
    - [Map columns in Delta tables to columns in related Parquet
      tables](delta-column-mapping.md)
  - [Track changes to a Delta table (change data
    feed)](delta-change-data-feed.md)
  - [Copy or clone a Delta table](delta-utility.md#clone-delta-table)
  - [Work with table constraints](delta-constraints.md#check-constraint)
  - Work with Delta table versions:
    - Query an earlier version of a Delta table (time travel): [quick
      start](quick-start.md#query-an-earlier-version-of-the-table-time-travel),
      [as part of batch data
      tasks](delta-batch.md#query-an-older-snapshot-of-a-table-time-travel)
    - [Restore or roll back a Delta table to an earlier
      version](delta-utility.md#restore-delta-table)
    - [Work with Delta table reader and writer versions](versioning.md)
  - Work with Delta table metadata:
    - [Read existing metadata](delta-batch.md#table-metadata)
    - [Add your own metadata](delta-batch.md#table-properties)
  - [Use Delta Lake SQL
    statements](/spark/latest/spark-sql/language-manual/index.md#delta-lake-statements)
  - [Use the Delta Lake API reference](delta-apidoc.md)
  - [Learn about Delta Lake concurrency control (ACID
    transactions)](concurrency-control.md)

  ## Resources

  - For answers to frequently asked questions, see [\_](delta-faq.md).
  - For reference information on Delta Lake SQL commands, see
    [\_](/spark/latest/spark-sql/language-manual/index.md#delta-lake-statements).
  - For further resources, including blog posts, talks, and examples, see
    [\_](delta-resources.md).

  For deep-dive training on Delta Lake, watch this YouTube video (2 hours, 42
  minutes).

  \

  .. youtube:: znv4rM9wevc?rel=0

  \
