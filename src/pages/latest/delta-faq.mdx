---
title: Frequently asked questions (FAQ)
description: Learn the answers to frequently asked questions about Delta Lake.
menu: docs
---

_In this article:_

- [What is Delta Lake?](/latest/delta-faq.html#what-is-delta-lake)

- [How is Delta Lake related to Apache Spark?](/latest/delta-faq.html#how-is-delta-lake-related-to-apache-spark)

- [What format does Delta Lake use to store data?](/latest/delta-faq.html#what-format-does-delta-lake-use-to-store-data)

- [How can I read and write data with Delta Lake?](/latest/delta-faq.html#how-can-i-read-and-write-data-with-delta-lake)

- [Where does Delta Lake store the data?](/latest/delta-faq.html#where-does-delta-lake-store-the-data)

- [Can I copy my Delta Lake table to another location?](/latest/delta-faq.html#can-i-copy-my-delta-lake-table-to-another-location)

- [Can I stream data directly into and from Delta tables?](/latest/delta-faq.html#can-i-stream-data-directly-into-and-from-delta-tables)

- [Does Delta Lake support writes or reads using the Spark Streaming DStream API?](/latest/delta-faq.html#does-delta-lake-support-writes-or-reads-using-the-spark-streaming-dstream-api)

- [When I use Delta Lake, will I be able to port my code to other Spark platforms easily?](/latest/delta-faq.html#when-i-use-delta-lake-will-i-be-able-to-port-my-code-to-other-spark-platforms-easily)

- [Does Delta Lake support multi-table transactions?](/latest/delta-faq.html#does-delta-lake-support-multi-table-transactions)

- [How can I change the type of a column?](/latest/delta-faq.html#how-can-i-change-the-type-of-a-column)

## What is Delta Lake?

[Delta Lake](https://delta.io/) is an [open source storage
layer](https://github.com/delta-io/delta) that brings reliability to [data
lakes](https://databricks.com/discover/data-lakes/introduction). Delta Lake
provides ACID transactions, scalable metadata handling, and unifies streaming
and batch data processing. Delta Lake runs on top of your existing data lake
and is fully compatible with Apache Spark APIs.

## How is Delta Lake related to Apache Spark?

Delta Lake sits on top of Apache Spark. The format and the compute layer
helps to simplify building big data pipelines and increase the overall
efficiency of your pipelines.

## What format does Delta Lake use to store data?

Delta Lake uses versioned Parquet files to store your data in your cloud
storage. Apart from the versions, Delta Lake also stores a transaction log to
keep track of all the commits made to the table or blob store directory to
provide ACID transactions.

## How can I read and write data with Delta Lake?

You can use your favorite Apache Spark APIs to read and write data with

Delta Lake. See [Read a table](/latest/delta-batch#deltadataframereads) and
[Write to a table](/latest/delta-batch#deltadataframewrites).

## Where does Delta Lake store the data?

When writing data, you can specify the location in your cloud storage.

Delta Lake stores the data in that location in Parquet format.

## Can I copy my Delta Lake table to another location?

Yes you can copy your Delta Lake table to another location. Remember to copy
files without changing the timestamps to ensure that the time travel with
timestamps will be consistent.

## Can I stream data directly into and from Delta tables?

Yes, you can use Structured Streaming to directly write data into Delta tables
and read from Delta tables. See [Stream data into Delta
tables](/latest/delta-streaming#stream-sink) and [Stream data from Delta
tables](/latest/delta-streaming#stream-source).

## Does Delta Lake support writes or reads using the Spark Streaming DStream API?

Delta does not support the DStream API. We recommend [Table streaming reads and writes](/latest/delta-streaming).

## When I use Delta Lake, will I be able to port my code to other Spark platforms easily?

Yes. When you use Delta Lake, you are using open Apache Spark APIs so you
can easily port your code to other Spark platforms. To port your code, replace
`delta` format with `parquet` format.

## Does Delta Lake support multi-table transactions?

Delta Lake does not support multi-table transactions and foreign keys.
Delta Lake supports transactions at the _table_ level.

## How can I change the type of a column?

Changing a column's type or dropping a column requires rewriting the table. For
an example, see [Change column type](delta-batch.md#change-column-type).
